{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "## Can we predict the ratings from the text features taken from reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "113SKYIWCM6m",
    "outputId": "f95d361b-1de9-44b0-f6fa-badd0659d6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in /opt/conda/lib/python3.7/site-packages (0.0.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle5\n",
    "import pickle5\n",
    "# import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn import decomposition, ensemble\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, GRU, Flatten\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import multiprocessing\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "base_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dAJzP7joCX36"
   },
   "outputs": [],
   "source": [
    "def read_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle5.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "h7pJ91KUCZPi",
    "outputId": "79dd6a39-7399-49e1-c9a7-bb826cf26999"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is definitely my favorite fast food sub s...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Really good place with simple decor, amazing f...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Awesome office and staff, very professional an...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  I love Deagan's. I do. I really do. The atmosp...    5.0\n",
       "1  Oh happy day, finally have a Canes near my cas...    4.0\n",
       "2  This is definitely my favorite fast food sub s...    5.0\n",
       "3  Really good place with simple decor, amazing f...    5.0\n",
       "4  Awesome office and staff, very professional an...    5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = read_pickle(base_dir + 'reviews_curtailed_4gb.pkl').reset_index()\n",
    "\n",
    "# Following line is for debugging purposes to reduce the data set size.\n",
    "# reviews_df = reviews_df[reviews_df.user_id.isin(reviews_df.groupby('user_id')['business_id'].count().sort_values(ascending=False).nlargest(50).reset_index().user_id)]\n",
    "\n",
    "reviews_df = reviews_df[['text', 'stars']]\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of review ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1HwY6qLURMZ",
    "outputId": "fefaad7b-3afd-4dfe-8a91-26a79f26a672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1.0     958596\n",
       "2.0     419709\n",
       "3.0     534070\n",
       "4.0    1085187\n",
       "5.0    2726027\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.groupby('stars')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = reviews_df['stars'].plot(kind='hist',subplots=True,sharex=True,sharey=True,title=\"Count of all the ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_n = sorted(list(reviews_df.stars.value_counts()))[0]\n",
    "fn = lambda row: row.loc[np.random.choice(row.index, downsampling_n, replace=True),:]\n",
    "reviews_df = reviews_df.groupby('stars', as_index=False).apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIMXe3O7UbF4",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "9667987e-8ca6-45b1-9524-572dcc2ccf6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1.0    419709\n",
       "2.0    419709\n",
       "3.0    419709\n",
       "4.0    419709\n",
       "5.0    419709\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.groupby('stars')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = reviews_df['stars'].plot(kind='hist',subplots=True,sharex=True,sharey=True,title=\"Count of all the ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test sets\n",
    "\n",
    "Converting the labels into one hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(reviews_df['text'], reviews_df['stars'])\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the combination of TF-IDF features parallelly (to save time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsDYpCsMFyS8",
    "outputId": "7ff5e681-c40c-4d22-8ae9-1df918aa43aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f4\n",
      "f1\n",
      "f2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:501: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f3\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "data_dict = manager.dict({})\n",
    "def f1(data_dict):\n",
    "    # word level tf-idf\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "    tfidf_vect.fit(reviews_df['text'])\n",
    "    xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "    xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "    data_dict[\"xtrain_tfidf\"] = xtrain_tfidf\n",
    "    data_dict[\"xvalid_tfidf\"] = xvalid_tfidf\n",
    "    print(\"f1\")\n",
    "\n",
    "def f2(data_dict):\n",
    "    # ngram level tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    tfidf_vect_ngram.fit(reviews_df['text'])\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "    xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "    data_dict[\"xtrain_tfidf_ngram\"] = xtrain_tfidf_ngram\n",
    "    data_dict[\"xvalid_tfidf_ngram\"] = xvalid_tfidf_ngram\n",
    "    print(\"f2\")\n",
    "\n",
    "def f4(data_dict):\n",
    "    # create a count vectorizer object \n",
    "    count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "    count_vect.fit(reviews_df['text'])\n",
    "    # transform the training and validation data using count vectorizer object\n",
    "    xtrain_count =  count_vect.transform(train_x)\n",
    "    xvalid_count =  count_vect.transform(valid_x)\n",
    "    data_dict[\"xtrain_count\"] = xtrain_count\n",
    "    data_dict[\"xvalid_count\"] = xvalid_count\n",
    "    print(\"f4\")\n",
    "\n",
    "p1 = multiprocessing.Process(target=f1, args=(data_dict,))\n",
    "p2 = multiprocessing.Process(target=f2, args=(data_dict,))\n",
    "p4 = multiprocessing.Process(target=f4, args=(data_dict,))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p4.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "p4.join()\n",
    "\n",
    "# Can't process the Character level in background because the output vector is too large to store in Manager dictionary.\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(reviews_df['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x)\n",
    "\n",
    "print(\"f3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the parallely generated TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tfidf = data_dict[\"xtrain_tfidf\"]\n",
    "xvalid_tfidf = data_dict[\"xvalid_tfidf\"]\n",
    "\n",
    "xtrain_tfidf_ngram = data_dict[\"xtrain_tfidf_ngram\"]\n",
    "xvalid_tfidf_ngram = data_dict[\"xvalid_tfidf_ngram\"]\n",
    "\n",
    "xtrain_count = data_dict[\"xtrain_count\"]\n",
    "xvalid_count = data_dict[\"xvalid_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the Embedding matrix and document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for i, line in enumerate(open(base_dir + 'wiki-news-300d-1M.vec', encoding=\"utf8\")):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(reviews_df['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# converting text into numerical features of vector length = 70\n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeing up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del reviews_df\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train method for all the Traditional Machine Learning based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    predictions = classifier.predict(feature_vector_valid)    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all the necessary variables in pickle format to restart training quicker in future (in cases of a failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuple_data.pkl\", \"wb\") as f:\n",
    "    pickle5.dump((xtrain_tfidf,xvalid_tfidf,xtrain_tfidf_ngram,xvalid_tfidf_ngram,xtrain_tfidf_ngram_chars,xvalid_tfidf_ngram_chars,xtrain_count,xvalid_count, train_y, valid_y), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuple_data.pkl\", \"rb\") as f:\n",
    "    (xtrain_tfidf,xvalid_tfidf,xtrain_tfidf_ngram,xvalid_tfidf_ngram,xtrain_tfidf_ngram_chars,xvalid_tfidf_ngram_chars,xtrain_count,xvalid_count, train_y, valid_y) = pickle5.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2tO7snRWH2z",
    "outputId": "14c46dda-43e2-496b-e722-6cd1db3318c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.5550485383226879\n",
      "NB, WordLevel TF-IDF:  0.5492273705438236\n",
      "NB, N-Gram Vectors:  0.5565772143405822\n",
      "NB, CharLevel Vectors:  0.5360906684050115\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hu0jKIf5WSMy",
    "outputId": "4f35ecab-5b06-413d-9487-77c2cc457e82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/rrokde/Carbonate/.conda/envs/search/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.6088667021197514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/rrokde/Carbonate/.conda/envs/search/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF:  0.6230422177619954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/rrokde/Carbonate/.conda/envs/search/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, N-Gram Vectors:  0.6048372493743293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/rrokde/Carbonate/.conda/envs/search/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, CharLevel Vectors:  0.6080261209178918\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.5983070199013795\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print(\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_y, xvalid_tfidf_ngram.tocsc())\n",
    "print(\"Xgb, N-gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False, epoch=10):\n",
    "    classifier.fit(feature_vector_train, label, epochs=10)\n",
    "    predictions = classifier.predict(feature_vector_valid)    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPN9OAxZYuAg",
    "outputId": "edbd1114-c8df-4468-c55e-fbebd6bab155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573908 samples\n",
      "Epoch 1/10\n",
      "1573908/1573908 [==============================] - 312s 198us/sample - loss: 0.9030\n",
      "Epoch 2/10\n",
      "1573908/1573908 [==============================] - 321s 204us/sample - loss: 0.8558\n",
      "Epoch 3/10\n",
      "1573908/1573908 [==============================] - 317s 202us/sample - loss: 0.8446\n",
      "Epoch 4/10\n",
      "1573908/1573908 [==============================] - 313s 199us/sample - loss: 0.8391\n",
      "Epoch 5/10\n",
      "1573908/1573908 [==============================] - 312s 198us/sample - loss: 0.8351\n",
      "Epoch 6/10\n",
      "1573908/1573908 [==============================] - 300s 191us/sample - loss: 0.8323\n",
      "Epoch 7/10\n",
      "1573908/1573908 [==============================] - 299s 190us/sample - loss: 0.8306\n",
      "Epoch 8/10\n",
      "1573908/1573908 [==============================] - 301s 191us/sample - loss: 0.8287\n",
      "Epoch 9/10\n",
      "1573908/1573908 [==============================] - 301s 191us/sample - loss: 0.8272\n",
      "Epoch 10/10\n",
      "1573908/1573908 [==============================] - 299s 190us/sample - loss: 0.8259\n",
      "CNN, Word Embeddings 0.6560383655746735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77    105077\n",
      "           1       0.56      0.65      0.60    104757\n",
      "           2       0.61      0.52      0.56    105280\n",
      "           3       0.61      0.53      0.57    105000\n",
      "           4       0.72      0.82      0.77    104523\n",
      "\n",
      "    accuracy                           0.66    524637\n",
      "   macro avg       0.66      0.66      0.65    524637\n",
      "weighted avg       0.66      0.66      0.65    524637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def CNN():\n",
    "    #Input Layer\n",
    "    input_layer = layers.Input((250, ))\n",
    "\n",
    "    #Word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    #Convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    #Pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss=SparseCategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "classifier = CNN()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)\n",
    "preds = classifier.predict(valid_seq_x)\n",
    "v = metrics.classification_report(valid_y, np.argmax(preds, axis = 1))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdDgziQYY9Vn",
    "outputId": "e6fae327-1329-4123-fe26-150132170ac6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573908 samples\n",
      "Epoch 1/10\n",
      "1573908/1573908 [==============================] - 273s 174us/sample - loss: 0.9481\n",
      "Epoch 2/10\n",
      "1573908/1573908 [==============================] - 271s 172us/sample - loss: 0.8769\n",
      "Epoch 3/10\n",
      "1573908/1573908 [==============================] - 270s 172us/sample - loss: 0.8621\n",
      "Epoch 4/10\n",
      "1573908/1573908 [==============================] - 272s 173us/sample - loss: 0.8552\n",
      "Epoch 5/10\n",
      "1573908/1573908 [==============================] - 271s 172us/sample - loss: 0.8509\n",
      "Epoch 6/10\n",
      "1573908/1573908 [==============================] - 272s 173us/sample - loss: 0.8471\n",
      "Epoch 7/10\n",
      "1573908/1573908 [==============================] - 271s 172us/sample - loss: 0.8452\n",
      "Epoch 8/10\n",
      "1573908/1573908 [==============================] - 270s 172us/sample - loss: 0.8433\n",
      "Epoch 9/10\n",
      "1573908/1573908 [==============================] - 270s 172us/sample - loss: 0.8418\n",
      "Epoch 10/10\n",
      "1573908/1573908 [==============================] - 272s 173us/sample - loss: 0.8403\n",
      "RNN-GRU, Word Embeddings 0.6458122473252935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75    105075\n",
      "           1       0.56      0.57      0.56    105113\n",
      "           2       0.58      0.57      0.57    104963\n",
      "           3       0.60      0.58      0.59    104518\n",
      "           4       0.75      0.77      0.76    104968\n",
      "\n",
      "    accuracy                           0.65    524637\n",
      "   macro avg       0.65      0.65      0.65    524637\n",
      "weighted avg       0.65      0.65      0.65    524637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def GRU():\n",
    "    # Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # GRU Layer\n",
    "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
    "\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss=SparseCategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "classifier = GRU()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-GRU, Word Embeddings\",  accuracy)\n",
    "preds = classifier.predict(valid_seq_x)\n",
    "v = metrics.classification_report(valid_y, np.argmax(preds, axis = 1))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXeoCP4sarVY",
    "outputId": "a4f285e1-14d3-4876-dd62-33a36d0d37f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573908 samples\n",
      "Epoch 1/10\n",
      "1573908/1573908 [==============================] - 432s 274us/sample - loss: 0.9409\n",
      "Epoch 2/10\n",
      "1573908/1573908 [==============================] - 419s 266us/sample - loss: 0.8639\n",
      "Epoch 3/10\n",
      "1573908/1573908 [==============================] - 442s 281us/sample - loss: 0.8475\n",
      "Epoch 4/10\n",
      "1573908/1573908 [==============================] - 463s 294us/sample - loss: 0.8386\n",
      "Epoch 5/10\n",
      "1573908/1573908 [==============================] - 460s 292us/sample - loss: 0.8337\n",
      "Epoch 6/10\n",
      "1573908/1573908 [==============================] - 441s 280us/sample - loss: 0.8294\n",
      "Epoch 7/10\n",
      "1573908/1573908 [==============================] - 419s 266us/sample - loss: 0.8272\n",
      "Epoch 8/10\n",
      "1573908/1573908 [==============================] - 420s 267us/sample - loss: 0.8251\n",
      "Epoch 9/10\n",
      "1573908/1573908 [==============================] - 422s 268us/sample - loss: 0.8240\n",
      "Epoch 10/10\n",
      "1573908/1573908 [==============================] - 421s 267us/sample - loss: 0.8232\n",
      "RNN-Bidirectional, Word Embeddings 0.6463268888774524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76    104516\n",
      "           1       0.54      0.60      0.57    104670\n",
      "           2       0.63      0.44      0.52    105104\n",
      "           3       0.60      0.59      0.60    105439\n",
      "           4       0.74      0.78      0.76    104908\n",
      "\n",
      "    accuracy                           0.65    524637\n",
      "   macro avg       0.64      0.65      0.64    524637\n",
      "weighted avg       0.64      0.65      0.64    524637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def GRU_bidirectional():\n",
    "    # Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
    "\n",
    "    # Output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss=SparseCategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "classifier = GRU_bidirectional()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-Bidirectional, Word Embeddings\",  accuracy)\n",
    "preds = classifier.predict(valid_seq_x)\n",
    "v = metrics.classification_report(valid_y, np.argmax(preds, axis = 1))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7yqJ781avSZ",
    "outputId": "43815a30-fd8f-4178-d1f2-c4e5a5689914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573908 samples\n",
      "Epoch 1/10\n",
      "1573908/1573908 [==============================] - 171s 109us/sample - loss: 0.9803\n",
      "Epoch 2/10\n",
      "1573908/1573908 [==============================] - 170s 108us/sample - loss: 0.9328\n",
      "Epoch 3/10\n",
      "1573908/1573908 [==============================] - 163s 103us/sample - loss: 0.9221\n",
      "Epoch 4/10\n",
      "1573908/1573908 [==============================] - 170s 108us/sample - loss: 0.9154\n",
      "Epoch 5/10\n",
      "1573908/1573908 [==============================] - 170s 108us/sample - loss: 0.9119\n",
      "Epoch 6/10\n",
      "1573908/1573908 [==============================] - 167s 106us/sample - loss: 0.9098\n",
      "Epoch 7/10\n",
      "1573908/1573908 [==============================] - 161s 102us/sample - loss: 0.9077\n",
      "Epoch 8/10\n",
      "1573908/1573908 [==============================] - 165s 105us/sample - loss: 0.9058\n",
      "Epoch 9/10\n",
      "1573908/1573908 [==============================] - 162s 103us/sample - loss: 0.9044\n",
      "Epoch 10/10\n",
      "1573908/1573908 [==============================] - 160s 102us/sample - loss: 0.9033\n",
      "CNN, Word Embeddings 0.62032605401449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74    104516\n",
      "           1       0.56      0.42      0.48    104670\n",
      "           2       0.54      0.56      0.55    105104\n",
      "           3       0.57      0.55      0.56    105439\n",
      "           4       0.72      0.76      0.74    104908\n",
      "\n",
      "    accuracy                           0.62    524637\n",
      "   macro avg       0.61      0.62      0.61    524637\n",
      "weighted avg       0.61      0.62      0.61    524637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def GRU_CNN():\n",
    "    # Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # GRU Bidirectional layer\n",
    "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    # Convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss=SparseCategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "classifier = GRU_CNN()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)\n",
    "preds = classifier.predict(valid_seq_x)\n",
    "v = metrics.classification_report(valid_y, np.argmax(preds, axis = 1))\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573908 samples\n",
      "Epoch 1/10\n",
      "1573908/1573908 [==============================] - 675s 429us/sample - loss: 0.9698\n",
      "Epoch 2/10\n",
      "1573908/1573908 [==============================] - 649s 413us/sample - loss: 0.8742\n",
      "Epoch 3/10\n",
      "1573908/1573908 [==============================] - 665s 422us/sample - loss: 0.8517\n",
      "Epoch 4/10\n",
      "1573908/1573908 [==============================] - 664s 422us/sample - loss: 0.8393\n",
      "Epoch 5/10\n",
      "1573908/1573908 [==============================] - 670s 426us/sample - loss: 0.8320\n",
      "Epoch 6/10\n",
      "1573908/1573908 [==============================] - 672s 427us/sample - loss: 0.8270\n",
      "Epoch 7/10\n",
      "1573908/1573908 [==============================] - 654s 416us/sample - loss: 0.8233\n",
      "Epoch 8/10\n",
      "1573908/1573908 [==============================] - 666s 423us/sample - loss: 0.8201\n",
      "Epoch 9/10\n",
      "1573908/1573908 [==============================] - 681s 433us/sample - loss: 0.8176\n",
      "Epoch 10/10\n",
      "1573908/1573908 [==============================] - 672s 427us/sample - loss: 0.8158\n",
      "RNN-LSTM, Word Embeddings 0.6573897761690464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76    104516\n",
      "           1       0.57      0.59      0.58    104670\n",
      "           2       0.61      0.54      0.57    105104\n",
      "           3       0.61      0.59      0.60    105439\n",
      "           4       0.75      0.79      0.77    104908\n",
      "\n",
      "    accuracy                           0.66    524637\n",
      "   macro avg       0.65      0.66      0.66    524637\n",
      "weighted avg       0.65      0.66      0.66    524637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def LSTM_LSTM():\n",
    "    # Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # LSTM Layer\n",
    "    lstm_layer = Bidirectional(layers.LSTM(60, return_sequences=True))(embedding_layer)\n",
    "\n",
    "    embedding_layer2 = layers.SpatialDropout1D(0.3)(lstm_layer)\n",
    "    lstm_layer1 = Bidirectional(layers.LSTM(50))(embedding_layer2)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer1)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss=SparseCategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "classifier = LSTM_LSTM()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-LSTM, Word Embeddings\",  accuracy)\n",
    "preds = classifier.predict(valid_seq_x)\n",
    "v = metrics.classification_report(valid_y, np.argmax(preds, axis = 1))\n",
    "print(v)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
